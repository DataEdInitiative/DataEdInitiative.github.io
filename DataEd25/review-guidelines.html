<!DOCTYPE HTML>
<!--
	Telephasic by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>DataEd 2024</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<link rel="stylesheet" href="../assets/css/2024.css" />
	</head>
	<body class="left-sidebar is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header-wrapper">
					<div id="header" class="container">

						<!-- Nav -->
							<nav id="nav">
								<ul>
									<li><a href="../index.html">DataEd Initiative Home</a></li>
									<li><a href="index.html">DataEd 2024</a></li>
									<li><a href="organization.html">Organization</a></li>
									<li><a href="submission.html">Submission info</a></li>
									<li><a href="program.html">Program</a></li>
								</ul>
							</nav>

					</div>
				</div>

			<!-- Main -->
				<div class="wrapper">
					<div class="container" id="main">

						<!-- Content -->
							<article id="content">
								<p>To make sure that all reviewers review in a consistent manner, we have derived a set of review guidelines from other conferences' guidelines. Please read the guidelines below carefully, and let us know if you have any questions. </p>

								<ul>
									<li><a href="#papers">Guidelines for research papers</a></li>
									<li><a href="#tools">Guidelines for tools and experience reports</a></li>
								</ul>


								<p>These review criteria are adapted from ICER (2023), the ACM Conference on International Computing Education Research, and from ITiCSE (2024), the ACM Conference on Innovation and Technology in Computer Science Education. Thank you to the original authors: Kathi Fisler, Paul Denny, Amy Ko, Anthony Robins and Jan Vahrenhold and other unknown contributors.</p>

<section id="papers">
<h3>Review Criteria for Research papers.</h3>
<p>We aim to evaluate papers against the following reviewing criteria, as independently as possible. These have been carefully chosen to be inclusive to many phenomena, epistemologies, and contribution types.</p>
<ul>
	<li><a href="#a">Criterion A: The submission is grounded in relevant prior work and leverages available theory when appropriate.</a></li>
	<li><a href="#b">Criterion B: The submission describes its methods and/or innovations sufficiently for others to understand how data was obtained, analyzed, and interpreted, or how an innovation works.</a></li>
	<li><a href="#c">Criterion C: The submission’s methods and/or innovations soundly address its research questions.
</a></li>
	<li><a href="#d">Criterion D: The submission advances knowledge of data systems education by addressing (possibly novel) questions that are of interest to the data systems education community.</a></li>
	<li><a href="#e">Criterion E: Discussion of results clearly summarizes the submission’s contributions beyond prior work and its implications for research and practice.</a></li>
	<li><a href="#f">Criterion F: The submission is written clearly enough to publish.</a></li>
</ul>
<p>To be published at DataEd, papers should be positively evaluated on all of these. The summary of this is another criterion:
<a href="#summary">Summary: Based on the criteria above, this paper should be published at DataEd.</a>
Below, we discuss each criterion in turn.
</p>
</section>

<section id="a">
<h3>Criterion A: The submission is grounded in relevant prior work and leverages available theory when appropriate.</h3>

<p><i>Papers should draw on relevant prior work and theories, and explicitly show how they are tied to the questions addressed. After reading the paper, one should feel more informed about prior literature and how that literature is related to the paper’s contributions. Such coverage of related work might come before a work’s contributions, or it might come after (e.g., connecting a new theory derived from observations to prior work. Note that not all types of research will have relevant theory to discuss, nor do all contribution types need theory to make significant advances. For example, a surprisingly robust but unexplained correlation might be an important discovery that later work could develop theory to explain. Reviewers should identify related work the authors might have missed and include pointers. Missing a paper that is relevant, but would not dramatically change the paper, is not sufficient grounds for rejecting a paper. Such citations can be added upon reviewers’ request prior to publication. Instead, criticism in reviews that leads to downgrading a paper should focus on missing prior work or theories that would significantly alter research questions, analysis, or interpretation of results.</i></p>

<b>Guidelines for Reviewers</b>
<p>Since prior work and theories needs to be covered sufficiently and in a meaningful way but not necessarily completely, reviewers are asked to do the following:</p>
<ul>
	<li>Refrain from downgrading work based on missing one or two peripherally related papers. Just note them, helping the authors to broaden their citations.</li>
	<li>Refrain from downgrading work based on not citing the reviewer’s own work, unless it really is objectively highly relevant.</li>
	<li>Refrain from downgrading work based on where in a paper they address prior work. Sometimes a dedicated section is appropriate, sometimes it is not. Sometimes prior work is better addressed at the end of a paper, not at the beginning.</li>
	<li>Make sure to critically note if work simply lists papers without meaningfully addressing their relevance to the paper’s questions or innovations.</li>
	<li>Refrain from downgrading work based on making discoveries inconsistent with theory. The point of empirical work is to test and refine theories, not conform to them.</li>
	<li>Refrain from downgrading work based on not building upon theory when there is no sufficient theory available that can be pointed out in the review. Conversely, if there is a missing and relevant theory, it should be named.</li>
	<li>Refrain from downgrading work based on not using the reviewer’s interpretation of a theory. Many theories have multiple competing interpretations and multiple distinct facets that can be seen from multiple perspectives.</li>
</ul>
</section>


<section id="b">
<h3>Criterion B: The submission describes its methods and/or innovations sufficiently for others to understand how data was obtained, analyzed, and interpreted, or how an innovation works.</h3>

<p><i>The paper should be self-contained in the sense that readers should be able to understand most of the key details about how the authors conducted their work or made their innovation possible. This is key for replication and meta-analysis of studies that come from positivist or post-positivist epistemologies. For interpretivist works, it is also key for what Checkland and Howell called “recoverability” (see Tracy et al. 2010 for a detailed overview for evaluating qualitative work). Reviews thus should focus on omissions of research process or innovation details that would significantly alter your judgment of the paper’s validity.</i></p>

<b>Guidelines for Reviewers</b>
<p>Since papers have to adhere to a word count limit and since there are always more details a paper can describe about methods, reviewers are asked to do the following: </p>
<ul>
	<li>Refrain from downgrading work based on not describing every detail. </li>
	<li>Refrain from asking authors to write substantially new method details unless you can identify content for them to cut, or there is space to add those details within the length restrictions. </li>
	<li>Refrain from asking authors of theory contributions for a traditional methods section; such contributions do not require them, as they are not empirical in nature. </li>
	<li>Feel free to ask authors for minor revisions that would support replication or meta-analysis for positivist or post-positivist works, and recoverability for interpretivist works using qualitative methods.</li>
</ul>
</section>


<section id="c">
<h3>Criterion C: The submission’s methods and/or innovations soundly address its research questions.</h3>

<p><i>The paper should answer the questions it poses, and it should do so with rigor, broadly construed. This is the single most important difference between research papers and other kinds of knowledge sharing in computing education (e.g., experience reports), and the source of certainty researchers can offer. Note that soundness is relative to claims. For example, if a paper claims to have provided evidence of causality, but its methods did not do that, that would be grounds for critique. But if a paper only claimed to have found a correlation, and that correlation is a notable discovery that future work could explain, downgrading it for not demonstrating causality would be inappropriate.</i></p>

<b>Guidelines for Reviewers</b>
<p>Since soundness is relative to claims and methods, reviewers are asked to do the following:</p>
<ul>
	<li>Refrain from applying criteria for quantitative methods to qualitative methods (e.g., critiquing a case study for a “small N” makes no sense; that is the point of a case study).</li>
	<li>Refrain from downgrading work based on a lack of a statistically significant difference if the study demonstrates sufficient power to detect a difference. A lack of difference can be discovery, too.</li>
	<li>Refrain from asking for the paper to do more than it claims if the demonstrated claims are sufficiently publishable (e.g., “I would publish this if it had also demonstrated knowledge transfer”).</li>
	<li>Refrain from relying on inexpert, anecdotal judgments (e.g., “I don’t know much about this but I played with it once and it didn’t work”).</li>
	<li>Refrain from assuming that because a method has not been used in computing education literature that it is not standard somewhere else. The field draws upon methods from many communities. Look for evidence that the method is used elsewhere.</li>
</ul>
</section>



<section id="d">
<h3>Criterion D: The submission advances knowledge of data education by addressing (possibly novel) questions that are of interest to the data systems education community.</h3>

<p><i>A paper can meet the previous criteria and still fail to advance what we know about the phenomena. It is up to the authors to convince you that the discoveries advance our knowledge in some way, e.g., by confirming uncertain prior work, adding a significant new idea, or making progress on a long-standing open question. Secondarily, there should be someone who might find the discovery interesting. It does not have to be interesting to a particular reviewer, and a particular reviewer does not have to be absolutely confident that an audience exists. As the PC cannot possibly reflect the broader audience of all readers, a probable audience is sufficient for publication.</i></p>

<b>Guidelines for Reviewers</b>
<p>Since advances can come in many forms, there are many criticisms that are inappropriate in isolation (if, however, many of these apply, they may justify rejection), and, thus, reviewers are asked to do the following:</p>
<ul>
	<li>Refrain from downgrading work because another, single paper was already published on the topic. Discoveries accumulate over many papers, not just one.</li>
	<li>Refrain from downgrading work that contributes a really new idea for not yet having everything figured out about it. Again, new discoveries may require multiple papers.</li>
	<li>Refrain from downgrading work because the results do not appear generalizable or were only obtained at a specific institution. Many papers explicitly discuss such limitations and possible remedies. Also, generalizability takes time, and, by their very nature, some qualitative methods do not lead to generalizable results.</li>
	<li>Refrain from downgrading work based on “only” being a replication. Replications, if done with diligence, are important.</li>
	<li>Refrain from downgrading work based on investigating phenomena you personally do not like (e.g., “I hate object-oriented languages, this work does not matter”).</li>
</ul>
</section>


<section id="e">
<h3>Criterion E: Discussion of results clearly summarizes the submission’s contributions beyond prior work and its implications for research and practice.</h3>

<p><i>It is the authors’ responsibility to help interpret the significance of a paper’s discoveries. If it makes significant advances, but does not explain what those advances are and why they matter, the paper is not ready for publication. That said, it is perfectly fine if you disagree with the paper’s interpretations or implications. Readers will vary on what they think a discovery means or what impact it might have on the world. All that is necessary is that the work presents some reasonably sound discussion of one possible set of interpretations.</i></p>

<b>Guidelines for Reviewers</b>
<p>Because there is no single “right” interpretation or discussion of implications, reviewers are asked to do the following:</p>
<ul>
	<li>Refrain from downgrading work because you do not think the idea would work in your institution.</li>
	<li>Refrain from downgrading work because you think that the impact is limited. Check the discussion of limitations and threats to validity and evaluate the paper with respect to the claims made.</li>
	<li>Make sure to critically note if work makes interpretations that are not grounded in evidence or proposes implications that are not grounded in evidence.</li>
</ul>



</section>



<section id="f">
<h3>Criterion F: The submission is written clearly enough to publish.</h3>
<p><i>Papers need to be clear and concise, both to be comprehensible to diverse audiences, but also to ensure the community is not overburdened by verboseness. We recognize that not all authors are fluent English writers; if, however, the paper requires significant editing to be comprehensible to fluent English readers, or it is unnecessarily verbose, it is not yet ready for publication.</i></p>

<b>Guidelines for Reviewers</b>
<p>Since submissions should be clear enough, reviewers are asked to do the following:</p>
<ul>
	<li>Refrain from downgrading work based on having easily fixed spelling and grammar issues.</li>
	<li>Refrain from downgrading a sufficiently clear paper because it could be clearer. All writing can be clearer in some way.</li>
	<li>Refrain from downgrading work based on not using all of the available word count. It is okay if a paper is short but significant.</li>
	<li>Refrain from asking for more detail unless you are certain there is space or - if there is not space - you can provide concrete suggestions for what to cut.</li>
</ul>
</section>




<section id="summary">
<h3>Summary: Based on the criteria above, this paper should be published at DataEd.</h3>
<p>Based on all of the previous criteria, decide how strongly you believe the paper should be accepted or rejected, assuming authors make any modest, straightforward minor revisions you and other reviewers request before publication. Papers that meet all of the criteria should be strongly accepted (though this does not imply that they are perfect). Papers that fail to meet most of the criteria should be strongly rejected. Each paper should be reviewed independently of others, as if it were a standalone journal submission. There are no conference presentation “slots”; there is no target acceptance rate. Neither should be a factor in reviewing individual submissions.</p>

<b>Guidelines for Reviewers</b>
<p>Because each paper should be judged on its own, reviewers are asked to do the following:</p>
<ul>
	<li>Refrain from recommending to accept a paper because it was the best in your set. It is possible that none of your papers sufficiently meet the criteria.</li>
	<li>Refrain from recommending to reject a paper because it should not take up a “slot”. The PC chairs will devise a program for however many papers sufficiently meet the criteria, whether that is 5 or 50. There is no need to preemptively design the program through your review; focus on the criteria.</li>
</ul>
</section>



<section id="tools">
<h3>Experience Reports (incl. Tools)</h3>
<p>As the focus of experience reports and tools is different from research papers, our reviews should be too. Most importantly, papers in this category may not have clear research questions or methodological descriptions. In your review, please reflect on the following questions:</p>

<ul>
	<li>Does the paper have 1+ goals (not RQs necessarily) stated goals in the paper? </li>
	<li>Are the observations clearly summarized?</li>
	<li>Do the authors talk about the implications of their findings?</li>
	<ul>
		<li>Does the paper include information on how to adopt or adapt teaching techniques and/or tools in other contexts or institutions?</li>
		<li>If the paper describes a tool: What are implications for future use of it?</li>
		<li>If the paper describes an experience: What are the implications of the results for teaching or computing education research</li>
	</ul>
	<li>Is the work of interest to the DataEd audience?</li>
	<ul>
		<li>Ensure that the work meets the scope of the workshop. </li>
		<li>Note that generic educational technology and applications of data systems for educational purposes are not in scope, except where they are used for data systems education.</li>
	</ul>
	
</ul>

<p>Please also evaluate the submission over <a href="#a">Criterion A</a>, <a href="#e">Criterion E</a> and <a href="#f">Criterion F</a>.</p>

</section>
								
				


							</article>

							
							
						</div>
					</div>
				</div>

			<!-- Footer -->
				<div id="footer-wrapper">
					<div id="copyright" class="container">
						<ul class="menu">
							<li>&copy; DataEdInitiative. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						</ul>
					</div>
				</div>

		</div>

		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/jquery.dropotron.min.js"></script>
			<script src="../assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>

	</body>
</html>
